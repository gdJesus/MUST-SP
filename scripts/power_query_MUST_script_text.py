# -*- coding: utf-8 -*-
import pandas as pd
import re
from PyPDF2 import PdfReader
import os

class PDFAnnotationLinker:
    """
    Esta classe foi projetada para analisar o texto de um PDF, identificar
    as tabelas de MUST e extrair informa√ß√µes espec√≠ficas:
    - O C√≥d ONS e a Instala√ß√£o de cada linha que cont√©m uma anota√ß√£o nos dados.
    - O texto completo de cada anota√ß√£o.
    - O objetivo √© criar um v√≠nculo direto entre uma linha de dados e a
      condi√ß√£o textual que se aplica a ela, ignorando anota√ß√µes no nome da Instala√ß√£o.
    """

    def __init__(self, pdf_path: str):
        """
        O construtor da classe. Ele √© executado assim que criamos um objeto.
        Sua fun√ß√£o √© preparar tudo para a extra√ß√£o.

        Args:
            pdf_path (str): O caminho para o arquivo PDF que queremos processar.
        """
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"O arquivo n√£o foi encontrado: {pdf_path}")
        
        self.pdf_path = pdf_path
        self.raw_text = self._extract_text_from_pdf()

        # --- DEFINI√á√ÉO DAS EXPRESS√ïES REGULARES (REGEX) ---
        # As express√µes regulares (regex) s√£o a ferramenta mais poderosa para este tipo de extra√ß√£o,
        # pois permitem encontrar padr√µes complexos em textos.

        # 1. Regex para encontrar o t√≠tulo de uma tabela.
        self.table_regex = re.compile(r'Tabela\s+([0-9A-Z.]+)\s*-\s*(.*)')

        # 2. Regex para encontrar a defini√ß√£o de uma anota√ß√£o (ex: "(A) - ...").
        self.annotation_regex = re.compile(r'^\s*\(([A-Z])\)\s*-\s*(.*)')

        # 3. Regex para identificar o in√≠cio de uma linha de dados pelo C√≥d ONS.
        self.row_start_regex = re.compile(r'^(SP[A-Z0-9\s-]+(?:--?[A-Z])?)\s+.*')
        
        # 4. Regex AVAN√áADA para extrair todas as partes de uma linha de dados.
        #    Ela usa "grupos nomeados" (?P<nome>...) para facilitar a extra√ß√£o.
        self.data_row_regex = re.compile(
            r'^(?P<cod_ons>SP[A-Z0-9\s-]+(?:--?[A-Z])?)\s+'  # Captura o C√≥d ONS
            r'(?P<instalacao>.*?)\s+'                          # Captura a Instala√ß√£o (n√£o-guloso)
            r'(?P<tensao>\d{2,3})\s+'                           # Captura a Tens√£o (2 ou 3 d√≠gitos)
            r'(?P<de>\d{1,2}/[A-Za-z]{3})\s+'                   # Captura a data de in√≠cio (ex: 1/Jan)
            r'(?P<ate>\d{1,2}/[A-Za-z]{3})\s+'                   # Captura a data de fim (ex: 31/Dez)
            r'(?P<must_data>.*)'                               # Captura todo o resto da linha (os dados MUST)
        )

    def _extract_text_from_pdf(self) -> str:
        """
        Fun√ß√£o auxiliar para ler o arquivo PDF e extrair todo o texto.
        """
        print(f"üìÑ Lendo o arquivo: {os.path.basename(self.pdf_path)}...")
        text = ""
        try:
            reader = PdfReader(self.pdf_path)
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
            print("‚úÖ Texto extra√≠do com sucesso.")
            return text
        except Exception as e:
            print(f"‚ùå Erro ao ler o PDF: {e}")
            return ""

    def link_annotations_to_codes(self) -> pd.DataFrame:
        """
        Esta √© a fun√ß√£o principal. Ela orquestra todo o processo de extra√ß√£o e vincula√ß√£o.
        """
        print("üîç Vinculando anota√ß√µes aos c√≥digos ONS...")
        lines = self.raw_text.split('\n')
        all_linked_data = []
        
        table_starts = [i for i, line in enumerate(lines) if self.table_regex.search(line)]

        if not table_starts:
            print("üî¥ Nenhuma tabela no formato 'Tabela XX - ...' foi encontrada.")
            return pd.DataFrame()

        for i, start_index in enumerate(table_starts):
            end_index = table_starts[i + 1] if i + 1 < len(table_starts) else len(lines)
            block_lines = lines[start_index:end_index]
            
            table_match = self.table_regex.search(block_lines[0])
            table_number = table_match.group(1)
            table_title = table_match.group(2).strip()
            print(f"\n  -> Processando Tabela {table_number}: {table_title}")

            annotations_map = self._extract_annotations_from_block(block_lines)
            if not annotations_map:
                print("    - Nenhuma defini√ß√£o de anota√ß√£o (ex: '(A) - ...') encontrada para esta tabela.")
                continue

            processed_lines = self._merge_wrapped_data_lines(block_lines)

            for line in processed_lines:
                match = self.data_row_regex.match(line)
                
                if match:
                    data = match.groupdict()
                    cod_ons = data['cod_ons']
                    instalacao = data['instalacao'].strip()
                    must_data = data['must_data']

                    found_letters = set(re.findall(r'\(([A-Z])\)', must_data))
                    
                    if found_letters:
                        for letter in sorted(list(found_letters)):
                            if letter in annotations_map:
                                all_linked_data.append({
                                    "Num_Tabela": table_number,
                                    "C√≥d ONS": cod_ons,
                                    "Instala√ß√£o": instalacao,
                                    "Letra": letter,
                                    "Anotacao": annotations_map[letter]
                                })
        
        if not all_linked_data:
            print("üî¥ Nenhuma anota√ß√£o foi encontrada dentro das colunas de dados das tabelas.")
            return pd.DataFrame()

        print(f"\nüìä {len(all_linked_data)} v√≠nculos entre C√≥d ONS e anota√ß√µes foram criados.")
        return pd.DataFrame(all_linked_data)

    def _merge_wrapped_data_lines(self, block_lines: list) -> list:
        """
        Fun√ß√£o auxiliar para juntar linhas de dados que foram quebradas.
        """
        merged_lines = []
        i = 0
        while i < len(block_lines):
            line = block_lines[i].strip()
            if self.row_start_regex.match(line):
                j = i + 1
                while j < len(block_lines):
                    next_line = block_lines[j].strip()
                    if next_line and not any([
                        self.table_regex.search(next_line),
                        self.annotation_regex.match(next_line),
                        self.row_start_regex.match(next_line)
                    ]):
                        line += " " + next_line
                        j += 1
                    else:
                        break
                merged_lines.append(line)
                i = j
            else:
                i += 1
        return merged_lines

    def _extract_annotations_from_block(self, block_lines: list) -> dict:
        """
        Esta fun√ß√£o recebe um bloco de texto e retorna um dicion√°rio mapeando
        cada letra de anota√ß√£o ao seu texto completo.
        """
        annotations = {}
        i = 0
        while i < len(block_lines):
            line = block_lines[i].strip()
            match = self.annotation_regex.match(line)
            if match:
                letter = match.group(1)
                text = match.group(2).strip()
                
                j = i + 1
                while j < len(block_lines):
                    next_line = block_lines[j].strip()
                    if next_line and not self.annotation_regex.match(next_line):
                        text += " " + next_line
                        j += 1
                    else:
                        break
                annotations[letter] = text
                i = j
            else:
                i += 1
        return annotations

    def to_excel(self, df: pd.DataFrame, output_path: str):
        """
        Exporta o DataFrame para um arquivo Excel.
        """
        if df.empty:
            print("Nenhum dado para exportar.")
            return
        try:
            df.to_excel(output_path, index=False, engine='xlsxwriter')
            print(f"üíæ Planilha de anota√ß√µes vinculadas salva com sucesso em: {output_path}")
        except Exception as e:
            print(f"‚ùå Erro ao salvar a planilha: {e}")

def clean_final_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    Limpa o DataFrame final para separar corretamente 'C√≥d ONS' e 'Instala√ß√£o'.
    Esta fun√ß√£o √© chamada antes de exportar para o Excel.

    Args:
        df (pd.DataFrame): O DataFrame gerado pela extra√ß√£o.

    Returns:
        pd.DataFrame: O DataFrame com as colunas corrigidas.
    """
    print("üßπ Limpando e separando colunas do DataFrame final...")
    
    df_copy = df.copy()

    # Regex para capturar o C√≥d ONS (primeira palavra) e o resto (Instala√ß√£o)
    # da coluna 'C√≥d ONS' que atualmente cont√©m ambos.
    # ^(SP\S+) -> Captura o grupo 1: Come√ßa com SP e vai at√© o primeiro espa√ßo.
    # \s+(.*)  -> Captura o grupo 2: Pega todo o resto da string ap√≥s o espa√ßo.
    pattern = re.compile(r'^(SP\S+)\s+(.*)')

    # Aplica a extra√ß√£o em cada linha da coluna 'C√≥d ONS'
    # expand=True cria novas colunas no DataFrame para cada grupo capturado
    extracted_data = df_copy['C√≥d ONS'].str.extract(pattern)

    # Verifica se a extra√ß√£o produziu as duas colunas esperadas
    if not extracted_data.empty and extracted_data.shape[1] == 2:
        # Renomeia as novas colunas
        extracted_data.columns = ['C√≥d ONS_limpo', 'Instala√ß√£o_extraida']
        
        # Atualiza o DataFrame original com os dados limpos
        # Usamos .loc para garantir que estamos modificando o df_copy
        df_copy.loc[:, 'C√≥d ONS'] = extracted_data['C√≥d ONS_limpo']
        df_copy.loc[:, 'Instala√ß√£o'] = extracted_data['Instala√ß√£o_extraida']
    else:
        print("‚ö†Ô∏è N√£o foi poss√≠vel aplicar a separa√ß√£o de C√≥d ONS e Instala√ß√£o. Verifique o padr√£o da regex.")

    print("‚úÖ Limpeza conclu√≠da.")
    return df_copy

def process_single_pdf(pdf_path: str, output_folder: str):
    """
    Fun√ß√£o de orquestra√ß√£o para processar um √∫nico arquivo PDF.
    """
    print(f"\n{'='*50}\nProcessando arquivo: {os.path.basename(pdf_path)}\n{'='*50}")
    
    linker = PDFAnnotationLinker(pdf_path=pdf_path)
    final_df = linker.link_annotations_to_codes()

    if not final_df.empty:
        # Chama a nova fun√ß√£o de limpeza antes de exportar
        cleaned_df = clean_final_df(final_df)

        base_name = os.path.splitext(os.path.basename(pdf_path))[0]
        output_excel_path = os.path.join(output_folder, f"saida_anotacoes_{base_name}.xlsx")

        print("\nüìã Preview dos dados vinculados (ap√≥s limpeza):")
        print(cleaned_df.head())

        linker.to_excel(cleaned_df, output_excel_path)

def process_folder(input_folder: str, output_folder: str):
    """
    Fun√ß√£o de orquestra√ß√£o para processar todos os PDFs em uma pasta.
    """
    pdf_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.pdf')]

    if not pdf_files:
        print(f"Nenhum arquivo PDF encontrado na pasta: {input_folder}")
        return

    for pdf_file in pdf_files:
        pdf_path = os.path.join(input_folder, pdf_file)
        process_single_pdf(pdf_path, output_folder)



# --- PONTO DE PARTIDA DO SCRIPT ---
if __name__ == "__main__":
    
    # --- CONFIGURA√á√ÉO ---

    mode = "folder"  # Pode ser "single" ou "folder"

    # Caminho para a pasta onde est√£o seus arquivos
    input_folder = r"C:\Users\pedrovictor.veras\OneDrive - Operador Nacional do Sistema Eletrico\Documentos\ESTAGIO_ONS_PVRV_2025\AUTOMAC√ïES ONS\arquivos"
    
    # Nome do arquivo espec√≠fico a ser usado no modo "single"
    single_file_name = "CUST-2002-123-41 - JAGUARI - RECON 2025-2028.pdf"

    # Pasta para salvar os resultados
    output_folder = os.path.join(input_folder, "anotacoes_extraidas")
    os.makedirs(output_folder, exist_ok=True)

    # --- EXECU√á√ÉO ---
    if mode == "single":
        pdf_path = os.path.join(input_folder, single_file_name)
        if os.path.exists(pdf_path):
            process_single_pdf(pdf_path, output_folder)
        else:
            print(f"ERRO: O arquivo '{single_file_name}' n√£o foi encontrado na pasta de entrada.")
    
    elif mode == "folder":
        process_folder(input_folder, output_folder)
        
    else:
        print(f"ERRO: Modo '{mode}' inv√°lido. Use 'single' ou 'folder'.")

    # --- FIM DO SCRIPT ---
    print("\nüîö script de automa√ß√£o de extra√ß√£o de texto conclu√≠do.")